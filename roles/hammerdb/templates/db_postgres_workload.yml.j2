---
apiVersion: batch/v1
kind: Job
metadata:
  name: "{{ ansible_operator_meta.name }}-workload-{{ trunc_uuid }}"
  namespace: "{{ operator_namespace }}"
spec:
  backoffLimit: 0
  activeDeadlineSeconds: {{ workload_args.job_timeout|default(3600) }}
  template:
    metadata:
      labels:
        app: hammerdb_workload-{{ trunc_uuid }}
        type: {{ ansible_operator_meta.name }}-bench-workload-{{ trunc_uuid }}
        benchmark-uuid: {{ uuid }}
{% if workload_args.annotations is defined or workload_args.client_annotations is defined %}
      annotations:
{% for annotation, value in workload_args.annotations.items() %}
        "{{annotation}}": "{{value}}"
{% endfor %}
{% for annotation, value in workload_args.client_annotations.items() %}
        "{{annotation}}": "{{value}}"
{% endfor %}
{% endif %}
    spec:
{% if workload_args.pin is sameas true %}
      nodeSelector:
        kubernetes.io/hostname: '{{ workload_args.pin_node }}'
{% endif %}
{% if workload_args.runtime_class is defined %}
      runtimeClassName: "{{ workload_args.runtime_class }}"
{% endif %}
      containers:
      - name: hammerdb
{% if workload_args.resources is sameas true %}
        resources:
          requests:
            cpu: {{ workload_args.requests_cpu | default("200m") }}
            memory: {{ workload_args.requests_memory | default("100Mi") }}
          limits:
            cpu: {{ workload_args.limits_cpu }}
            memory: {{ workload_args.limits_memory }}
{% endif %}
        image: {{ workload_args.image | default('quay.io/cloud-bulldozer/hammerdb:master') }}
        imagePullPolicy: Always
        env:
          - name: uuid
            value: "{{ uuid }}"
          - name: test_user
            value: "{{ test_user | default("ripsaw") }}"
          - name: clustername
            value: "{{ clustername }}"
{% if elasticsearch.url %}
          - name: es
            value: "{{ elasticsearch.url }}"
          - name: es_index
            value: "{{ elasticsearch.index_name | default("ripsaw-hammerdb") }}"
          - name: parallel
            value: "{{ elasticsearch.parallel | default(false) }}"
{% endif %}
{% if prometheus is defined %}
          - name: prom_es
            value: "{{ prometheus.es_url }}"
          - name: prom_parallel
            value: "{{ prometheus.es_parallel | default(false) }}"
          - name: prom_token
            value: "{{ prometheus.prom_token | default() }}"
          - name: prom_url
            value: "{{ prometheus.prom_url | default() }}"
{% endif %}
        command: ["/bin/sh", "-c"]
        args:
          - "/usr/local/bin/uid_entrypoint;
             export db_type={{workload_args.db_type}};
             export timed_test={{workload_args.timed_test}};
             export db_server={{workload_args.db_server}};
             export db_port={{workload_args.db_port}};
             export db_warehouses={{workload_args.db_warehouses}};
             export db_num_workers={{workload_args.db_num_workers}};
             export db_user={{workload_args.db_user}};
             export db_name={{workload_args.db_user}};
             export transactions={{workload_args.transactions}};
             export raiseerror={{workload_args.raiseerror}};
             export keyandthink={{workload_args.keyandthink}};
             export driver={{workload_args.driver}};
             export rampup={{workload_args.rampup}};
             export runtime={{workload_args.runtime}};
             export allwarehouse={{workload_args.allwarehouse}};
             export timeprofile={{workload_args.timeprofile}};
             export async_scale={{workload_args.async_scale}};
             export async_client={{workload_args.async_client}};
             export async_verbose={{workload_args.async_verbose}};
             export async_delay={{workload_args.async_delay}};
             export samples={{workload_args.samples}};
             export db_postgresql_defaultdbase={{workload_args.db_postgresql_defaultdbase}};
             export db_postgresql_superuser={{workload_args.db_postgresql_superuser}};
             export db_postgresql_superuser_pass={{workload_args.db_postgresql_superuser_pass}};
             export db_postgresql_vacuum={{workload_args.db_postgresql_vacuum}};
             export db_postgresql_dritasnap={{workload_args.db_postgresql_dritasnap}};
             export db_postgresql_oracompat={{workload_args.db_postgresql_oracompat}};
             export db_postgresql_storedprocs={{workload_args.db_postgresql_storedprocs}};
{% if workload_args.es_custom_field is sameas true %}
             export es_ocp_version={{workload_args.es_ocp_version}};
             export es_cnv_version={{workload_args.es_cnv_version}};
             export es_db_version={{workload_args.es_db_version}};
             export es_os_version={{workload_args.es_os_version}};
             export es_kind={{workload_args.es_kind}};
{% endif %}
             cd /hammer;
             run_snafu --tool hammerdb -u {{ uuid }}"
        volumeMounts:
        - name: hammerdb-workload-volume
          mountPath: "/workload"
          readOnly: false
      volumes:
      - name: hammerdb-workload-volume
        configMap:
          name: "{{ ansible_operator_meta.name }}-workload-{{ trunc_uuid }}"
          defaultMode: 0640
      restartPolicy: Never
{% include "metadata.yml.j2" %}
