---
kind: Job
apiVersion: batch/v1
metadata:
  name: '{{ meta.name }}-uperf-client-{{item.status.podIP}}'
  namespace: '{{ operator_namespace }}'
spec:
  ttlSecondsAfterFinished: 600
  template:
    metadata:
      labels:
        app: uperf-bench-client
    spec:
{% if uperf.hostnetwork %}
      hostNetwork : true
      serviceAccountName: benchmark-operator
      serviceAccount: benchmark-operator
{% endif %}
      containers:
      - name: benchmark
        image: "quay.io/cloud-bulldozer/uperf:latest"
        command: ["/bin/sh", "-c"]
        args:
          - "export h={{item.status.podIP}};
{% if elasticsearch is defined %}
{% if elasticsearch.server is defined %}
             export es={{elasticsearch.server}};
             export es_port={{elasticsearch.port}};
             export uuid={{uuid}};
{% endif %}
{% endif %}
{% if test_user is defined %}
             export test_user={{test_user}};
{% endif %}
             export hostnet={{uperf.hostnetwork}};
             export ips=$(hostname -I);
             while true; do
               if [[ $(redis-cli -h {{bo.resources[0].status.podIP}} get start) =~ 'true' ]]; then
                 for file in $(ls /tmp/uperf-test/ | egrep ^uperf); do
                   cat /tmp/uperf-test/$file;
                   for i in `seq 1 {{uperf.samples}}`; do
                     python /opt/snafu/uperf-wrapper/uperf-wrapper.py -w /tmp/uperf-test/$file -r $i;
                   done;
                 done;
               else
                 continue;
               fi;
               break;
             done;
             redis-cli -h {{bo.resources[0].status.podIP}} set start false"
        volumeMounts:
          - name: config-volume
            mountPath: "/tmp/uperf-test"
      volumes:
        - name: config-volume
          configMap:
            name: uperf-test
      restartPolicy: OnFailure
{% if uperf.pin %}
      nodeSelector:
          kubernetes.io/hostname: '{{ uperf.pin_client }}'
{% endif %}
