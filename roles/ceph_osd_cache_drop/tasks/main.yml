---
- debug:
    msg: "in ceph OSD cache dropper role"

# First ensure that toolbox pod is running

- name: check for existing rook-ceph cluster
  k8s_info:
    kind: Pod
    namespace: "{{ rook_ceph_namespace }}"
    label_selectors:
      - app = rook-ceph-mgr
  register: rook_ceph_mgr_exists

- name: generate boolean for namespace existence
  set_fact:
    rook_ceph_cluster_exists: "{{ rook_ceph_mgr_exists.resources | length > 0 }}"

- debug:
    var: rook_ceph_cluster_exists

- fail:
    msg: "You are asking for Ceph cache with drop_cache_rook_ceph: true in CR, but there is no ceph cluster!"
  when: not rook_ceph_cluster_exists

#- name: get pod info of pre-existing ceph toolbox pod
#  k8s_info:
#    kind: Pod
#    label_selectors:
#      - app = rook-ceph-tools
#    namespace: "{{ rook_ceph_namespace }}"
#  register: ceph_toolbox_already_exists

#- debug:
#    var: ceph_toolbox_already_exists

# FIXME: next commented-out task gets 403 unprivileged error
# workaround is to issue oc command (with admin privs) to do it
#   oc patch OCSInitialization ocsinit -n openshift-storage --type json --patch  
#      '[{ "op": "replace", "path": "/spec/enableCephTools", "value": true }]'

#- name: ensure Ceph OSD toolbox pod is started
#  k8s:
#    namespace: "{{ rook_ceph_namespace }}"
#    name: ocsinit
#    kind: OCSInitialization
#    state: present
#    apply: true
#    resource_definition:
#      spec:
#        enableCephTools: true  
#  when: ceph_toolbox_already_exists.resources | length == 0

#- name: wait for toolbox pod to start
#  shell: "python3 /opt/ansible/roles/ceph_osd_cache_drop/wait_for_pod.py 30 {{ rook_ceph_namespace }} ceph-toolbox"
#  when: ceph_toolbox_already_exists.resources | length == 0

- name: get pod name of running ceph toolbox pod
  k8s_info:
    kind: Pod
    label_selectors:
      - app = rook-ceph-tools
    namespace: "{{ rook_ceph_namespace }}"
  register: ceph_toolbox

#- debug:
#    var: ceph_toolbox

# this next var is referenced by the YAML that creates the cache dropper pod

- name: put pod id into a var
  set_fact:
    rook_ceph_toolbox_pod: "{{ ceph_toolbox.resources[0].metadata.name }}"

- debug:
    var: rook_ceph_toolbox_pod


# now ensure that ceph cache dropper pod is started and we have its IP

#- name: get pre-existing ceph cache dropper pod
#  k8s_info:
#    kind: Pod
#    label_selectors:
#      - app = rook-ceph-osd-cache-drop
#    namespace: "{{ rook_ceph_namespace }}"
#  register: drop_pod_already_exists

#- debug:
#    var: drop_pod_already_exists

# FIXME: this gets 403 unprivileged error
# workaround is to issue oc create -f command (with admin privs) to do it
# you must substitute a real value for the jinja2 var in this template first

#- name: start ceph OSD cache dropper
#  k8s:
#    definition: "{{ lookup('template', '/opt/ansible/roles/ceph_osd_cache_drop/rook_ceph_drop_cache_pod.yaml') | from_yaml }}"
#  register: ceph_cache_dropper_start
#  when: drop_pod_already_exists.resources | length == 0
#
#- name: wait for cache dropper to start
#  shell: "python3 /opt/ansible/roles/ceph_osd_cache_drop/wait_for_pod.py 30 {{ rook_ceph_namespace }} rook-ceph-osd-cache-drop"
#  when: rook_ceph_cluster_exists and drop_pod_already_exists.resources | length == 0

- name: get cache dropper pod
  k8s_info:
    kind: Pod
    label_selectors:
      - app = rook-ceph-osd-cache-drop
    namespace: "{{ rook_ceph_namespace }}"
  register: ceph_osd_cache_drop_pod

#- debug:
#    var: ceph_osd_cache_drop_pod

- name: put ip into a var
  set_fact:
    ceph_osd_cache_drop_pod_ip: "{{ ceph_osd_cache_drop_pod.resources[0].status.podIP }}"

- debug:
    var: ceph_osd_cache_drop_pod_ip

- name: test IP
  shell: "curl http://{{ ceph_osd_cache_drop_pod_ip }}:{{ ceph_cache_drop_svc_port }}/"
  register: drop_pod_test

#- debug:
#    var: drop_pod_test

