---

- name: A1 Get current state
  k8s_facts:
    api_version: ripsaw.cloudbulldozer.io/v1alpha1
    kind: Benchmark
    name: '{{ meta.name }}'
    namespace: '{{ operator_namespace }}'
  register: resource_state

- operator_sdk.util.k8s_status:
    api_version: ripsaw.cloudbulldozer.io/v1alpha1
    kind: Benchmark
    name: "{{ meta.name }}"
    namespace: "{{ operator_namespace }}"
    status:
      state: Building
      complete: false
  when: resource_state.resources[0].status.state is not defined

- name: A3 Get current state - If it has changed
  k8s_facts:
    api_version: ripsaw.cloudbulldozer.io/v1alpha1
    kind: Benchmark
    name: '{{ meta.name }}'
    namespace: '{{ operator_namespace }}'
  register: resource_state

- name: A4 Capture operator information
  k8s_facts:
    kind: Pod
    api_version: v1
    namespace: '{{ operator_namespace }}'
    label_selectors:
      - name = benchmark-operator
  register: bo

- name: A5 Capture ServiceIP
  k8s_facts:
    kind: Service
    api_version: v1
    namespace: '{{ operator_namespace }}'
    label_selectors:
      - type = uperf-bench-server-{{ trunc_uuid }}
  register: serviceip
  when: workload_args.serviceip is defined and workload_args.serviceip

#
# "pin" mode exists prior to "scale" mode. If "pin: true", we will
# do the old way using pin_server and pin_client
#
- name: A6 Record num server (V1) pods using workload_args.pair - TBD
  set_fact:
      num_server_pods: "{{ workload_args.pair | default('1')|int }}"
  when: workload_args.max_node is not defined

####

- name: A7 V2 Setup eligible node (static) list - Tobe replaced by real node list builder
  set_fact:
      worker_node_list: "{{workload_args.node_list}}"

- name: A8 V2 Record num server pods using new worker_node_list
  set_fact:
      num_server_pods: "{{ worker_node_list|length * workload_args.density | default('1')|int }}"
  when: workload_args.max_node is defined

- name: A8_1 show num_server_pods
  debug:
      var: num_server_pods

- block:

  - name: P8 Create service for server pods
    k8s:
      definition: "{{ lookup('template', 'service.yml.j2') | from_yaml }}"
    with_sequence: start=0 count={{ workload_args.pair | default('1')|int }}
    when: workload_args.serviceip is defined and workload_args.serviceip

  - name: P9 Start Server(s)
    k8s:
      definition: "{{ lookup('template', 'server.yml.j2') | from_yaml }}"
    register: servers
    with_sequence: start=0 count={{ workload_args.pair | default('1')|int }}
    when: workload_args.max_node is not defined

############ <V2>

  - name: P10 V2 Start Server(s) - total = eligible nodes * density
    k8s:
       definition: "{{ lookup('template', 'server.yml.j2') | from_yaml }}"
    with_nested:
      - "{{ worker_node_list }}" 
      - "{{ range(0, workload_args.density | default('1'|int)) | list }}"
    when: workload_args.max_node is defined

############ </V2>

  - name: P11 Wait for pods to be running....
    k8s_facts:
      kind: Pod
      api_version: v1
      namespace: '{{ operator_namespace }}'
      label_selectors:
        - type = uperf-bench-server-{{ trunc_uuid }}
    register: server_pods

  - name: P12 Update resource state
    operator_sdk.util.k8s_status:
      api_version: ripsaw.cloudbulldozer.io/v1alpha1
      kind: Benchmark
      name: "{{ meta.name }}"
      namespace: "{{ operator_namespace }}"
      status:
        state: "Starting Servers"

  when: resource_state.resources[0].status.state == "Building" and resource_kind == "pod"
 
########### <VM block>
# VM remains scale agnostic for now
###########
- block:

  - name: V11 Start Server(s)
    k8s:
      definition: "{{ lookup('template', 'server_vm.yml.j2') | from_yaml }}"
    register: servers
    with_sequence: start=0 count={{ workload_args.pair | default('1')|int }}

  - name: V12 Wait for vms to be running....
    k8s_facts:
      kind: VirtualMachineInstance
      api_version: kubevirt.io/v1alpha3
      namespace: '{{ operator_namespace }}'
      label_selectors:
        - type = uperf-bench-server-{{ trunc_uuid }}
    register: server_vms

  - name: V13 Update resource state
    operator_sdk.util.k8s_status:
      api_version: ripsaw.cloudbulldozer.io/v1alpha1
      kind: Benchmark
      name: "{{ meta.name }}"
      namespace: "{{ operator_namespace }}"
      status:
        state: "Starting Servers"

  when: resource_state.resources[0].status.state == "Building" and resource_kind == "vm"

########### </VM vlock>

########### <POD> mode
- block:

  - name: P13 Get server pods
    k8s_facts:
      kind: Pod
      api_version: v1
      namespace: '{{ operator_namespace }}'
      label_selectors:
        - type = uperf-bench-server-{{ trunc_uuid }}
    register: server_pods

  - name: P14 Update resource state
    operator_sdk.util.k8s_status:
      api_version: ripsaw.cloudbulldozer.io/v1alpha1
      kind: Benchmark
      name: "{{ meta.name }}"
      namespace: "{{ operator_namespace }}"
      status:
        state: "Starting Clients"
    when: "num_server_pods|int  == server_pods | json_query('resources[].status[]')|selectattr('phase','match','Running')|list|length"
    #when: "workload_args.pair|default('1')|int == server_pods | json_query('resources[].status[]')|selectattr('phase','match','Running')|list|length"


  when: resource_state.resources[0].status.state == "Starting Servers" and resource_kind == "pod"

######## </POD>
#
######## <VM>
- block:

  - name: V14 Wait for vms to be running....
    k8s_facts:
      kind: VirtualMachineInstance
      api_version: kubevirt.io/v1alpha3
      namespace: '{{ operator_namespace }}'
      label_selectors:
        - type = uperf-bench-server-{{ trunc_uuid }}
    register: server_vms

  - name: V15 Update resource state
    operator_sdk.util.k8s_status:
      api_version: ripsaw.cloudbulldozer.io/v1alpha1
      kind: Benchmark
      name: "{{ meta.name }}"
      namespace: "{{ operator_namespace }}"
      status:
        state: "Starting Clients"
    #when: "workload_args.pair|default('1')|int == server_vms | json_query('resources[].status[]')|selectattr('phase','match','Running')|list|length and workload_args.pair|default('1')|int  == (server_vms | json_query('resources[].status.interfaces[0].ipAddress')|length)"
    when: "num_server_pods|int == server_vms | json_query('resources[].status[]')|selectattr('phase','match','Running')|list|length and num_server_pods|int  == (server_vms | json_query('resources[].status.interfaces[0].ipAddress')|length)"

  - name: V16 blocking client from running uperf
    command: "redis-cli set start false"
    with_items: "{{ server_vms.resources }}"
    #when: "workload_args.pair|default('1')|int == server_vms | json_query('resources[].status[]')|selectattr('phase','match','Running')|list|length and workload_args.pair|default('1')|int  == (server_vms | json_query('resources[].status.interfaces[0].ipAddress')|length)"
    when: "num_server_pods|int == server_vms | json_query('resources[].status[]')|selectattr('phase','match','Running')|list|length and num_server_pods|int == (server_vms | json_query('resources[].status.interfaces[0].ipAddress')|length)"

  when: resource_state.resources[0].status.state == "Starting Servers" and resource_kind == "vm"

#### </VM block>

- block:   #HN while state is "start client" for pod

  - name: A17 Get pod info
    k8s_facts:
      kind: Pod
      api_version: v1
      namespace: '{{ operator_namespace }}'
      label_selectors:
        - type = uperf-bench-server-{{ trunc_uuid }}
    register: server_pods

  - name: A18 Generate uperf xml files
    k8s:
      definition: "{{ lookup('template', 'configmap.yml.j2') | from_yaml }}"

  - block:   # Starting Clients"
    - set_fact:
        cpod_affi_list: []

    - block:
      - name: HN colocate TBD
        debug:
            msg: "HN colocate TBD"
      when: workload_args.colocate is defined and workload_args.colocate|bool == True

    #### generate affinity list
    - block:

      - name: Pass 1 - Build client list for node[1:]
        set_fact:
            cpod_affi_list: "{{ cpod_affi_list  + [ item[0]] }}"
        with_nested:
            - "{{ worker_node_list[1:] }}"
            - "{{ range(0, workload_args.density | default('1'|int)) | list }}"

      - name: HNC_0 debug cpod_list
        debug:
              var: cpod_affi_list

      - name: Pass 2 - Append client list with node[0] to the end
        set_fact:
            cpod_affi_list: "{{cpod_affi_list  + [ item[0] ] }}"
        with_nested:
            - "{{ worker_node_list[0] }}"
            - "{{ range(0, workload_args.density | default('1'|int)) | list }}"


      - name: HNC_1 debug cpod_list
        debug:
              var: cpod_affi_list 


      when: workload_args.colocate is not defined or workload_args.colocate|bool == False
    #### End generate cpod affinity list
    
    - name: P19 Start Client(s) w/o serviceIP
      k8s:
        definition: "{{ lookup('template', 'workload.yml.j2') | from_yaml }}"
      with_together: 
        - "{{ server_pods.resources }}"
        - "{{ cpod_affi_list }}"
      when: workload_args.serviceip is defined and not workload_args.serviceip|default('false') and server_pods.resources|length > 0

    - name: P20 Start Client(s) with serviceIP
      k8s:
        definition: "{{ lookup('template', 'workload.yml.j2') | from_yaml }}"
      with_together: 
        - "{{ serviceip.resources }}"
        - "{{ cpod_affi_list }}"

      when: workload_args.serviceip is defined and workload_args.serviceip and serviceip.resources|length > 0

    - name: compare worker000 versus pin_server
      debug:
          msg: "HN equal"
      when: worker_node_list[0] == workload_args.pin_server 

    when: resource_kind == "pod"
 
  - block:

    - name: V19 Wait for vms to be running....
      k8s_facts:
        kind: VirtualMachineInstance
        api_version: kubevirt.io/v1alpha3
        namespace: '{{ operator_namespace }}'
        label_selectors:
          - type = uperf-bench-server-{{ trunc_uuid }}
      register: server_vms

    - name: V20 Generate uperf test files
      k8s:
        definition: "{{ lookup('template', 'configmap_script.yml.j2') | from_yaml }}"
      with_items: "{{ server_vms.resources }}"

    - name: V21 Start Client(s)
      k8s:
        definition: "{{ lookup('template', 'workload_vm.yml.j2') | from_yaml }}"
      with_items: "{{ server_vms.resources }}"
      when: server_vms.resources|length > 0

    when: resource_kind == "vm"

  - operator_sdk.util.k8s_status:
      api_version: ripsaw.cloudbulldozer.io/v1alpha1
      kind: Benchmark
      name: "{{ meta.name }}"
      namespace: "{{ operator_namespace }}"
      status:
        state: Waiting for Clients

  when: resource_state.resources[0].status.state == "Starting Clients"

- block:

  - block: # Pod block
    - name: P22 Get client pod status
      k8s_facts:
        kind: Pod
        api_version: v1
        namespace: '{{ operator_namespace }}'
        label_selectors:
          - app = uperf-bench-client-{{ trunc_uuid }}
      register: client_pods

    - name: P23 Update resource state
      operator_sdk.util.k8s_status:
        api_version: ripsaw.cloudbulldozer.io/v1alpha1
        kind: Benchmark
        name: "{{ meta.name }}"
        namespace: "{{ operator_namespace }}"
        status:
          state: Clients Running
      when: "num_server_pods|int == client_pods | json_query('resources[].status[]')|selectattr('phase','match','Running')|list|length and num_server_pods|int == (client_pods | json_query('resources[].status.podIP')|length)"
      #when: "workload_args.pair|default('1')|int == client_pods | json_query('resources[].status[]')|selectattr('phase','match','Running')|list|length and workload_args.pair|default('1')|int  == (client_pods | json_query('resources[].status.podIP')|length)"

  - block: #V block

    - name: V22 set complete to false
      command: "redis-cli set complete false"

    - name: V23  Get count of clients ready
      command: "redis-cli get clients-{{ trunc_uuid }}"
      register: clients_ready_count

    - name: V24 Update resource state
      operator_sdk.util.k8s_status:
        api_version: ripsaw.cloudbulldozer.io/v1alpha1
        kind: Benchmark
        name: "{{ meta.name }}"
        namespace: "{{ operator_namespace }}"
        status:
          state: Clients Running
      when: "workload_args.pair|default('1')|int == clients_ready_count.stdout|int"

    - name: V14 debug state
      debug: 
        msg: "HN ater V24 {{ resource_state.resources[0].status.state }}"

    when: resource_kind == "vm"


  when: resource_state.resources[0].status.state == "Waiting for Clients"

- block:  #ALL state = Clients running

  - name: A25 Signal workload
    command: "redis-cli set start true"

  - name: A26 Update resource state
    operator_sdk.util.k8s_status:
      api_version: ripsaw.cloudbulldozer.io/v1alpha1
      kind: Benchmark
      name: "{{ meta.name }}"
      namespace: "{{ operator_namespace }}"
      status:
        state: "Running"

  when: resource_state.resources[0].status.state == "Clients Running"

- block:
  - block:
    - name: P27 Waiting for pods to complete....
      k8s_facts:
        kind: pod
        api_version: v1
        namespace: '{{ operator_namespace }}'
        label_selectors:
          - app = uperf-bench-client-{{ trunc_uuid }}
      register: client_pods

    - operator_sdk.util.k8s_status:
        api_version: ripsaw.cloudbulldozer.io/v1alpha1
        kind: Benchmark
        name: "{{ meta.name }}"
        namespace: "{{ operator_namespace }}"
        status:
          state: Cleanup
          complete: false
          #when: "workload_args.pair|default('1')|int == (client_pods|json_query('resources[].status[]')|selectattr('phase','match','Succeeded')|list|length)"
      when: "num_server_pods|int == (client_pods|json_query('resources[].status[]')|selectattr('phase','match','Succeeded')|list|length)"
    when: resource_kind == "pod"

  - block:

    - name: V28 get complete
      command: "redis-cli get complete"
      register: complete_status

    - operator_sdk.util.k8s_status:
        api_version: ripsaw.cloudbulldozer.io/v1alpha1
        kind: Benchmark
        name: "{{ meta.name }}"
        namespace: "{{ operator_namespace }}"
        status:
          state: Cleanup
          complete: false
      when: complete_status.stdout == "true"
    when: resource_kind == "vm"

  when: resource_state.resources[0].status.state == "Running"

- block:

  - block:
    - name: P29 Get Server Pods
      k8s_facts:
        kind: Pod
        api_version: v1
        namespace: '{{ operator_namespace }}'
        label_selectors:
          - type = uperf-bench-server-{{ trunc_uuid }}
      register: server_pods

    - name: P30 Pod names - to clean
      set_fact:
        clean_pods: |
            [
            {% for item in server_pods.resources %}
              "{{ item['metadata']['name'] }}",
            {% endfor %}
            ]

    - name: P31 Cleanup run
      k8s:
        kind: pod
        api_version: v1
        namespace: '{{ operator_namespace }}'
        state: absent
        name: "{{ item }}"
      with_items: "{{ clean_pods }}"
      when: cleanup
    when: resource_kind == "pod"

  - name: delete redis keys
    command: "redis-cli del {{ item }}"
    loop:
      - "{{ trunc_uuid }}"
      - "clients-{{ trunc_uuid }}"

  - operator_sdk.util.k8s_status:
      api_version: ripsaw.cloudbulldozer.io/v1alpha1
      kind: Benchmark
      name: "{{ meta.name }}"
      namespace: "{{ operator_namespace }}"
      status:
        state: Complete
        complete: true

  when: resource_state.resources[0].status.state == "Cleanup"
