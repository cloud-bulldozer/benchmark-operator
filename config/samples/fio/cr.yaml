apiVersion: ripsaw.cloudbulldozer.io/v1alpha1
kind: Benchmark
metadata:
  name: fio-benchmark-example
  namespace: ripsaw-system
spec:
  # where elastic search is running
  elasticsearch:
    url: http://my.elasticsearch.server:80
    verify_cert: false
    parallel: false
  # clustername: myk8scluster
  # test_user: ripsaw
  workload:
    name: "fio_distributed"
    args:
      # if true, do large sequential write to preallocate volume before using
      prefill: true
      # for compressed volume uncomment the next line and make the cmp_bs same as bs
      # prefill_bs: 8KiB
      # number of times each test
      samples: 3
      # number of fio pods generating workload
      servers: 3
      # put all fio pods on this server
      pin_server: ''
      # test types, see fio documentation
      jobs:
        - write
        - read
        - randwrite
        - randread
      # I/O request sizes (also called block size)
      bs:
        - 4KiB
        - 64KiB
      # how many fio processes per pod
      numjobs:
        - 1
      # with libaio ioengine, number of in-flight requests per process
      iodepth: 4
      # how long to run read tests, this is TOO SHORT DURATION
      read_runtime: 15
      # how long to run write tests, this is TOO SHORT DURATION
      write_runtime: 15
      # don't start measuring until this many seconds pass, for reads
      read_ramp_time: 5
      # don't start measuring until this many seconds pass, for writes
      write_ramp_time: 5
      # size of file to access
      filesize: 2GiB
      # interval between i/o stat samples in milliseconds
      log_sample_rate: 3000
      #storageclass: rook-ceph-block
      #storagesize: 5Gi
      #rook_ceph_drop_caches: True
      #rook_ceph_drop_cache_pod_ip: 192.168.111.20
#######################################
#  EXPERT AREA - MODIFY WITH CAUTION  #
#######################################
#  global_overrides:
#  NOTE: Dropping caches as per this example can only be done if the
#        fio server is running in a privileged pod
#    - exec_prerun=bash -c 'sync && echo 3 > /proc/sys/vm/drop_caches'
  job_params:
    - jobname_match: write
      params:
        - fsync_on_close=1
        - create_on_open=1
        - runtime={{ workload_args.write_runtime }}
        - ramp_time={{ workload_args.write_ramp_time }}
    - jobname_match: read
      params:
        - time_based=1
        - runtime={{ workload_args.read_runtime }}
        - ramp_time={{ workload_args.read_ramp_time }}
    - jobname_match: rw
      params:
        - rwmixread=50
        - time_based=1
        - runtime={{ workload_args.read_runtime }}
        - ramp_time={{ workload_args.read_ramp_time }}
    - jobname_match: readwrite
      params:
        - rwmixread=50
        - time_based=1
        - runtime={{ workload_args.read_runtime }}
        - ramp_time={{ workload_args.read_ramp_time }}
    - jobname_match: randread
      params:
        - time_based=1
        - runtime={{ workload_args.read_runtime }}
        - ramp_time={{ workload_args.read_ramp_time }}
    - jobname_match: randwrite
      params:
        - time_based=1
        - runtime={{ workload_args.write_runtime }}
        - ramp_time={{ workload_args.write_ramp_time }}
    - jobname_match: randrw
      params:
        - time_based=1
        - runtime={{ workload_args.write_runtime }}
        - ramp_time={{ workload_args.write_ramp_time }}
#    - jobname_match: <search_string>
#      params:
#        - key=value
